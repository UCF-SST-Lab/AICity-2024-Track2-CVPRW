id: train_wts_ped_event_pdvcl

vocab_size: 3499
dict_file: data/vocabulary/vocabulary_bdd_pedestrian.json


visual_feature_type: clip
visual_feature_folder: 'data/wts_features'


feature_dim: 768
invalid_video_json: []
train_proposal_file: data/generated_proposals/dbg_trainval_top100.json
eval_proposal_file: data/generated_proposals/dbg_trainval_top100.json


train_caption_file: 'data/captions/wts_trainval_vehicle_view_caption_pedestrian_event.json'
val_caption_file: 'data/captions/wts_trainval_vehicle_view_caption_pedestrian_event.json'

gt_file_for_eval: ['data/captions/wts_trainval_vehicle_view_caption_pedestrian_event.json', 'data/captions/wts_trainval_vehicle_view_caption_pedestrian_event.json']
gt_file_for_auc: 'data/captions/wts_trainval_vehicle_view_caption_pedestrian_event.json'
gt_file_for_para_eval: ['data/captions/wts_entities_val_vehicle_view_caption_pedestrain_event.json', 'data/captions/wts_entities_val_vehicle_view_caption_pedestrain_event.json']



train_proposal_type: gt
gt_proposal_sample_num: 30
sample_method: nearest

batch_size: 4
lr: 0.0005 
learning_rate_decay_start: 10
learning_rate_decay_every: 10
learning_rate_decay_rate: 0.5
weight_decay: 0.0 
save_all_checkpoint: 0
save_checkpoint_every: 9

num_queries: 10 #10
dec_layers: 3
enc_layers: 3
transformer_ff_dim: 512 
transformer_dropout_prob: 0.1
frame_embedding_num: 100
caption_decoder_type: light
att_hid_size: 0

with_box_refine: 1

fix_xcw: 1
set_cost_caption: 0
set_cost_giou: 4
set_cost_bbox: 0
set_cost_class: 2
caption_loss_coef: 2
giou_loss_coef: 4
bbox_loss_coef: 0
cls_loss_coef: 2
count_loss_coef: 0.5
max_eseq_length: 10
lloss_cross_entropy: 0
lloss_focal_loss: 0
lloss_gau_mask: 1

batch_size_for_eval: 1
max_caption_len: 300
max_eseq_length: 10


num_layers: 2
min_epoch_when_save: 1

epoch: 30
