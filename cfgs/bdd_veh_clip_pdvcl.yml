id: bdd_veh_clip_pdvcl

vocab_size: 2448
dict_file: data/vocabulary/vocabulary_bdd_vehicle.json

visual_feature_type: clip
visual_feature_folder: 'data/bdd_features'

feature_dim: 768
invalid_video_json: []
train_proposal_file: data/generated_proposals/dbg_trainval_top100.json
eval_proposal_file: data/generated_proposals/dbg_trainval_top100.json


gt_file_for_eval: ['data/captions/bdd_select_val_caption_vehicle.json', 'data/captions/bdd_select_val_caption_vehicle.json']
gt_file_for_auc: 'data/captions/bdd_select_val_caption_vehicle.json'
gt_file_for_para_eval: ['data/captions/bdd_entities_select_val_caption_vehicle.json', 'data/captions/bdd_entities_select_val_caption_vehicle.json']
train_caption_file: 'data/captions/bdd_trainval_caption_vehicle.json'
val_caption_file: 'data/captions/bdd_select_val_caption_vehicle.json'



train_proposal_type: gt
gt_proposal_sample_num: 30
sample_method: nearest

batch_size: 4
lr: 0.001
learning_rate_decay_start: 10
learning_rate_decay_every: 10
learning_rate_decay_rate: 0.5
weight_decay: 0.0001
save_all_checkpoint: 0
save_checkpoint_every: 10

num_queries: 10 
dec_layers: 2 
enc_layers: 2  
transformer_ff_dim: 512 
transformer_dropout_prob: 0.1
frame_embedding_num: 100
caption_decoder_type: light
att_hid_size: 0

with_box_refine: 1

fix_xcw: 1
set_cost_caption: 0
set_cost_giou: 4
set_cost_bbox: 0
set_cost_class: 2
caption_loss_coef: 2
giou_loss_coef: 4
bbox_loss_coef: 0
cls_loss_coef: 2
count_loss_coef: 0.5
max_eseq_length: 10
lloss_cross_entropy: 0
lloss_focal_loss: 0
lloss_gau_mask: 1

batch_size_for_eval: 1
max_caption_len: 300
max_eseq_length: 10


num_layers: 2
min_epoch_when_save: 1

epoch: 51
